# ğŸ’¬ Tweet Sentiment Analyzer

A Machine Learning & Deep Learning project to classify tweets into **Positive**, **Negative**, or **Neutral** sentiments using:

- âœ… Logistic Regression with TF-IDF
- âœ… Deep Learning with LSTM
- âœ… Clean UI with Streamlit

---

## ğŸ§  Models Used

| Model Type              | Description                                  |
| ----------------------- | -------------------------------------------- |
| **Logistic Regression** | Simple ML model using TF-IDF vectorization   |
| **LSTM**                | Deep Learning model using Keras & embeddings |

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ streamlit_app/
â”‚ â””â”€â”€ app.py # Streamlit web app
â”œâ”€â”€ data/
â”‚ â””â”€â”€ tweets.csv # Raw dataset
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ logistic_model.py # Logistic Regression code
â”‚ â”œâ”€â”€ lstm_model.py # LSTM model code
â”‚ â””â”€â”€ saved_models/ # Trained models and tokenizer
â”‚ â”œâ”€â”€ logistic_model.pkl
â”‚ â”œâ”€â”€ tfidf_vectorizer.pkl
â”‚ â”œâ”€â”€ lstm_model.h5
â”‚ â””â”€â”€ tokenizer.json
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ preprocessing.py # Text cleaning with NLTK
â”œâ”€â”€ main.py # Run both models from here
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”§ Features

| Feature                | Description                               |
| ---------------------- | ----------------------------------------- |
| **TF-IDF + Logistic**  | Fast traditional ML baseline              |
| **LSTM Model**         | Deep learning for improved accuracy       |
| **NLTK Preprocessing** | Cleaning, stopword removal, tokenization  |
| **Streamlit Web App**  | Easy and interactive sentiment prediction |

---

## âš™ï¸ Installation

1. **Clone the repo:**

```bash
git clone https://github.com/your-username/tweet-sentiment-analyzer.git
cd tweet-sentiment-analyzer
```

2. **Create a virtual environment (Python 3.10+):**

```bash
python -m venv tweet_env
tweet_env\Scripts\activate    # Windows
# source tweet_env/bin/activate   # Mac/Linux
```

3. **Install dependencies:**

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Run Models

1. **Train Models & Save:**

```bash
python main.py
```

âœ… This creates:

- models/saved_models/lstm_model.h5

- models/saved_models/tokenizer.json

- models/saved_models/logistic_model.pkl

- models/saved_models/tfidf_vectorizer.pkl

---

## ğŸŒ Run Streamlit App

```bash
streamlit run streamlit_app/app.py
```

- Enter a tweet in the input box

- Choose a model (default is LSTM)

- Get predicted sentiment with confidence scores

---

## ğŸ“¦ Requirements

All dependencies are listed in requirements.txt. Major libraries:

- tensorflow
- scikit-learn
- nltk
- streamlit
- pandas

---

## ğŸ“Š Dataset

We use the Sentiment140 dataset (160k tweets) with pre-labeled sentiments:

- 0 â†’ Negative
- 2 â†’ Neutral
- 4 â†’ Positive

Dataset link: [Sentiment140 on Kaggle](https://www.kaggle.com/datasets/kazanova/sentiment140)

---

## ğŸ™‹â€â™‚ï¸ Author

**Tilak Savani**  
Masterâ€™s in Computer Science, University of Georgia  
Domain: Artificial Intelligence & Machine Learning

---

## â­ Credits

- [NLTK](https://www.nltk.org/)
- [Scikit-learn](https://scikit-learn.org/)
- [TensorFlow](https://www.tensorflow.org/)
- [Streamlit](https://streamlit.io/)

---

## ğŸ“„ License

This project is open-source and available under the **MIT License**.
